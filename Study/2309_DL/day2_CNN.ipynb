{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 15524708427629997363\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 2909221684\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 4863385509044985658\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import InputLayer, Conv2D, AveragePooling2D, Flatten, Dense, ZeroPadding2D\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(-1, 28, 28, 1)\n",
    "x_test = x_test.reshape(-1, 28, 28, 1)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2)\n",
    "\n",
    "x_train = x_train / 255.0\n",
    "x_val = x_val / 255.0\n",
    "x_test = x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "LeNet = Sequential([InputLayer(input_shape = (28, 28, 1)),   # input layer\n",
    "                    \n",
    "                    ZeroPadding2D((2,2)),\n",
    "                    \n",
    "                    Conv2D(6, 5, activation='tanh'),\n",
    "                    AveragePooling2D(strides=2),\n",
    "\n",
    "                    Conv2D(16, 5, activation='tanh'),\n",
    "                    AveragePooling2D(strides=2),\n",
    "\n",
    "                    Conv2D(120, 5, activation='tanh'),\n",
    "                    Flatten(),\n",
    "\n",
    "                    Dense(84, activation='tanh'),\n",
    "                    Dense(10, activation='softmax')                    \n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "LeNet.compile(optimizer='SGD',\n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "              metrics = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " zero_padding2d (ZeroPaddin  (None, 32, 32, 1)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 28, 28, 6)         156       \n",
      "                                                                 \n",
      " average_pooling2d (Average  (None, 14, 14, 6)         0         \n",
      " Pooling2D)                                                      \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 10, 10, 16)        2416      \n",
      "                                                                 \n",
      " average_pooling2d_1 (Avera  (None, 5, 5, 16)          0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 1, 1, 120)         48120     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 120)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 84)                10164     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                850       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 61706 (241.04 KB)\n",
      "Trainable params: 61706 (241.04 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "LeNet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.2921 - accuracy: 0.9144\n",
      "Epoch 2/3\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.2303 - accuracy: 0.9322\n",
      "Epoch 3/3\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1877 - accuracy: 0.9449\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1d3935e2d50>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LeNet.fit(x_train, y_train, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1808 - accuracy: 0.9459\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1807662397623062, 0.9459166526794434]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LeNet.evaluate(x_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 files belonging to 2 classes.\n",
      "Found 5000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    directory = 'D:/dogs_vs_cats/dogs_vs_cats/train/',\n",
    "    labels = 'inferred',\n",
    "    label_mode = 'int',\n",
    "    batch_size = 32,\n",
    "    image_size = (227, 227)\n",
    ")\n",
    "\n",
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    directory = 'D:/dogs_vs_cats/dogs_vs_cats/test/',\n",
    "    labels = 'inferred',   # labels are generated from the directory structure\n",
    "    label_mode = 'int',    # 0 = cats, 1 = dogs\n",
    "    batch_size = 32,\n",
    "    image_size = (227, 227)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize\n",
    "def process(image, label):\n",
    "    image = tf.cast(image / 255., tf.float32)\n",
    "    return image, label\n",
    "\n",
    "train_ds = train_ds.map(process)\n",
    "test_ds = test_ds.map(process)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential(name='alex_net')\n",
    "model.add(Conv2D(filters=96, kernel_size=11,strides=4,activation='relu',input_shape=(227,227,3)))\n",
    "model.add(MaxPool2D(pool_size=3,strides=2))\n",
    "\n",
    "model.add(Conv2D(filters=256, kernel_size=5, activation='relu',padding=\"same\"))\n",
    "model.add(MaxPool2D(pool_size=3,strides=2))\n",
    "\n",
    "model.add(Conv2D(filters=384, kernel_size=3,strides=1,activation='relu',padding=\"same\"))\n",
    "model.add(Conv2D(filters=384,kernel_size=3,strides=1,activation='relu',padding=\"same\"))\n",
    "model.add(Conv2D(filters=256,kernel_size=3,strides=1,activation='relu',padding=\"same\"))\n",
    "model.add(MaxPool2D(pool_size=3,strides=2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096,activation='relu'))\n",
    "model.add(Dropout(0.5)) # dropout : 보통 Dense layer part에서 진행 \n",
    "model.add(Dense(4096,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "model.fit(train_ds, epochs=10, validation_data=test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "from pathlib import Path\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    directory = 'D:/dogs_vs_cats/dogs_vs_cats/train/',\n",
    "    labels = 'inferred',\n",
    "    label_mode = 'int',\n",
    "    batch_size = 32,\n",
    "    image_size = (224, 224)\n",
    ")\n",
    "\n",
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    directory = 'D:/dogs_vs_cats/dogs_vs_cats/test/',\n",
    "    labels = 'inferred',   \n",
    "    label_mode = 'int',    \n",
    "    batch_size = 32,\n",
    "    image_size = (224, 224)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_path = Path(\"D:/Brain_Tumor_Classification(MRI)/Training\")\n",
    "# test_path = Path(\"D:/Brain_Tumor_Classification(MRI)/Testing\")\n",
    "train_path = Path(\"D:/dogs_vs_cats/dogs_vs_cats/train/\")\n",
    "test_path = Path(\"D:/dogs_vs_cats/dogs_vs_cats/test/\")\n",
    "\n",
    "train_jpg_path = list(train_path.glob(r\"*/*.jpg\"))\n",
    "test_jpg_path = list(test_path.glob(r\"*/*.jpg\"))\n",
    "\n",
    "train_jpg_labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1],train_jpg_path))\n",
    "test_jpg_labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1],test_jpg_path))\n",
    "\n",
    "train_jpg_path_series = pd.Series(train_jpg_path,name=\"JPG\").astype(str)\n",
    "train_jpg_labels_series = pd.Series(train_jpg_labels,name=\"CATEGORY\").astype(str)\n",
    "\n",
    "test_jpg_path_series = pd.Series(test_jpg_path,name=\"JPG\").astype(str)\n",
    "test_jpg_labels_series = pd.Series(test_jpg_labels,name=\"CATEGORY\").astype(str)\n",
    "\n",
    "main_train_data = pd.concat([train_jpg_path_series, train_jpg_labels_series],axis=1)\n",
    "main_test_data = pd.concat([test_jpg_path_series, test_jpg_labels_series],axis=1)\n",
    "main_train_data = main_train_data.sample(frac=1).reset_index(drop=True)\n",
    "main_test_data = main_test_data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "train_img_generator = ImageDataGenerator(rescale=1./255,\n",
    "                                         rotation_range=25,\n",
    "                                         brightness_range=[0.3,0.7],\n",
    "                                         width_shift_range=0,\n",
    "                                         height_shift_range=0,\n",
    "                                         zoom_range=0)\n",
    "\n",
    "test_img_generator = ImageDataGenerator(rescale=1./255,\n",
    "                                        rotation_range=25,\n",
    "                                        brightness_range=[0.3,0.7],\n",
    "                                        width_shift_range=0,\n",
    "                                        height_shift_range=0,\n",
    "                                        zoom_range=0)\n",
    "\n",
    "train_ds = train_img_generator.flow_from_dataframe(dataframe=main_train_data,\n",
    "                                                   x_col=\"JPG\",\n",
    "                                                   y_col=\"CATEGORY\",\n",
    "                                                   color_mode=\"rgb\",\n",
    "                                                   class_mode=\"categorical\",\n",
    "                                                   batch_size=10,\n",
    "                                                   subset=\"training\",\n",
    "                                                   target_size=(227,227))\n",
    "\n",
    "test_ds = test_img_generator.flow_from_dataframe(dataframe=main_test_data,\n",
    "                                                 x_col=\"JPG\",\n",
    "                                                 y_col=\"CATEGORY\",\n",
    "                                                 color_mode='rgb',\n",
    "                                                 class_mode=\"categorical\",\n",
    "                                                 batch_size=10,\n",
    "                                                 subset=\"training\",\n",
    "                                                 target_size=(227,227))\n",
    "\n",
    "train_valid =train_img_generator.flow_from_dataframe(dataframe=main_train_data,\n",
    "                                                     x_col=\"JPG\",\n",
    "                                                     y_col=\"CATEGORY\",\n",
    "                                                     color_mode=\"rgb\",\n",
    "                                                     class_mode=\"categorical\",\n",
    "                                                     batch_size=10,\n",
    "                                                     subset=\"training\",\n",
    "                                                     target_size=(227,227))\n",
    "\n",
    "test_valid =test_img_generator.flow_from_dataframe(dataframe=main_test_data,\n",
    "                                                   x_col=\"JPG\",\n",
    "                                                   y_col=\"CATEGORY\",\n",
    "                                                   color_mode=\"rgb\",\n",
    "                                                   class_mode=\"categorical\",\n",
    "                                                   batch_size=10,\n",
    "                                                   subset=\"training\",\n",
    "                                                   target_size=(227,227))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg = Sequential(name=\"vgg16\")\n",
    "\n",
    "# input\n",
    "vgg.add(Conv2D(64,3, strides=1, activation=\"relu\", padding=\"same\", input_shape=(224, 224, 3)))\n",
    "vgg.add(Conv2D(64,3, strides=1, activation=\"relu\", padding=\"same\"))\n",
    "\n",
    "vgg.add(MaxPool2D(2,2))\n",
    "\n",
    "vgg.add(Conv2D(128,3, strides=1, activation=\"relu\", padding=\"same\"))\n",
    "vgg.add(Conv2D(128,3, strides=1, activation=\"relu\", padding=\"same\"))\n",
    "\n",
    "vgg.add(MaxPool2D(2,2))\n",
    "\n",
    "vgg.add(Conv2D(256,3, strides=1, activation=\"relu\", padding=\"same\"))\n",
    "vgg.add(Conv2D(256,3, strides=1, activation='relu', padding=\"same\"))\n",
    "vgg.add(Conv2D(256,1, strides=1, activation='relu', padding=\"same\"))\n",
    "\n",
    "vgg.add(MaxPool2D(2,2))\n",
    "\n",
    "vgg.add(Conv2D(512,3, strides=1, activation=\"relu\", padding=\"same\"))\n",
    "vgg.add(Conv2D(512,3, strides=1, activation='relu', padding=\"same\"))\n",
    "vgg.add(Conv2D(512,1, strides=1, activation='relu', padding=\"same\"))\n",
    "\n",
    "vgg.add(MaxPool2D(2,2))\n",
    "\n",
    "vgg.add(Conv2D(512,3, strides=1, activation=\"relu\", padding=\"same\"))\n",
    "vgg.add(Conv2D(512,3, strides=1, activation='relu', padding=\"same\"))\n",
    "vgg.add(Conv2D(512,1, strides=1, activation='relu', padding=\"same\"))\n",
    "\n",
    "vgg.add(MaxPool2D(2,2))\n",
    "\n",
    "# Flatten Layer\n",
    "vgg.add(Flatten())\n",
    "# FC Layer\n",
    "vgg.add(Dense(4096,activation='relu'))\n",
    "vgg.add(Dense(4096,activation='relu'))\n",
    "## vgg.add(Dense(1000,activation='relu')) # 몇 개로 분류할 건지 \n",
    "# vgg.add(Dense(4, activation=\"softmax\")) # 3개 이상 softmax\n",
    "vgg.add(Dense(1, activation=\"sigmoid\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"]) # loss=\"sparse_categorical_crossentropy\",\n",
    "vgg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg.fit(train_ds, train_valid, epochs=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lhs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
