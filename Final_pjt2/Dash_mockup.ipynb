{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dash\n",
    "from dash import dcc, html\n",
    "from dash.dependencies import Input, Output\n",
    "import base64\n",
    "import io\n",
    "import psycopg2\n",
    "\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "from moviepy.editor import VideoFileClip\n",
    "import dash_table\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "import plotly.express as px\n",
    "from wordcloud import WordCloud\n",
    "import plotly.graph_objects as go\n",
    "from matplotlib import pyplot as plt\n",
    "# plt.rcParams['font.family'] ='Malgun Gothic'\n",
    "plt.rcParams['axes.unicode_minus'] =False\n",
    "plt.rc('font', family='NanumGothic')\n",
    "plt.rc('font', family='NanumBarunGothic')\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\Github\\\\Genia\\\\Final_pjt2'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hslio\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hslio\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x20a2e064b50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "app = dash.Dash()\n",
    "\n",
    "df = pd.read_csv('./data/Iris.csv')\n",
    "fig = px.scatter(df, x=\"SepalWidth\", y=\"SepalLength\", color=\"Species\")\n",
    "\n",
    "with open('./Lecture_text/summarize/01강유리수의소수표현(1)_EBS중학뉴런수학2(상)_google_trans.txt', 'r', encoding='utf-8') as file:\n",
    "    text = file.read()\n",
    "# Preprocess the text data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "stop_words = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다', '.', ',', '(', ')', '!', '?', '-', '‘', '’', '“', '”', '…']\n",
    "word_tokens = word_tokenize(text.lower())\n",
    "filtered_text = [word for word in word_tokens if word.isalpha() and word not in stop_words]\n",
    "\n",
    "# Create a bar plot of the most frequent words\n",
    "word_counts = Counter(filtered_text)\n",
    "most_common_words = word_counts.most_common(10)\n",
    "nlp_fig1 = px.bar(x=[word[0] for word in most_common_words], y=[word[1] for word in most_common_words])\n",
    "\n",
    "# Create a histogram of word length\n",
    "word_lengths = [len(word) for word in filtered_text]\n",
    "nlp_fig2 = px.histogram(x=word_lengths, nbins=max(word_lengths))\n",
    "\n",
    "# Create a heatmap of term frequency\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(filtered_text)\n",
    "term_frequency = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "nlp_fig3 = px.imshow(term_frequency)\n",
    "\n",
    "# Create a network diagram\n",
    "bigrams = nltk.bigrams(filtered_text)\n",
    "bigram_freq = nltk.FreqDist(bigrams)\n",
    "bigram_df = pd.DataFrame(bigram_freq.items(), columns=[\"bigram\", \"freq\"])\n",
    "bigram_df = bigram_df.sort_values(by=\"freq\", ascending=False)\n",
    "\n",
    "G = nx.Graph()\n",
    "\n",
    "for index, row in bigram_df.iterrows():\n",
    "    G.add_edge(row[\"bigram\"][0], row[\"bigram\"][1], weight=row[\"freq\"])\n",
    "\n",
    "pos = nx.spring_layout(G)\n",
    "edge_x = []\n",
    "edge_y = []\n",
    "for edge in G.edges():\n",
    "    x0, y0 = pos[edge[0]]\n",
    "    x1, y1 = pos[edge[1]]\n",
    "    edge_x.append(x0)\n",
    "    edge_x.append(x1)\n",
    "    edge_x.append(None)\n",
    "    edge_y.append(y0)\n",
    "    edge_y.append(y1)\n",
    "    edge_y.append(None)\n",
    "\n",
    "edge_trace = go.Scatter(\n",
    "    x=edge_x, y=edge_y,\n",
    "    line=dict(width=0.5, color='#888'),\n",
    "    hoverinfo='none',\n",
    "    mode='lines')\n",
    "\n",
    "node_x = []\n",
    "node_y = []\n",
    "for node in G.nodes():\n",
    "    x, y = pos[node]\n",
    "    node_x.append(x)\n",
    "    node_y.append(y)\n",
    "\n",
    "node_trace = go.Scatter(\n",
    "    x=node_x, y=node_y,\n",
    "    mode='markers',\n",
    "    hoverinfo='text',\n",
    "    marker=dict(\n",
    "        showscale=True,\n",
    "        colorscale='YlGnBu',\n",
    "        reversescale=True,\n",
    "        color=[],\n",
    "        size=10,\n",
    "        colorbar=dict(\n",
    "            thickness=15,\n",
    "            title='Node Connections',\n",
    "            xanchor='left',\n",
    "            titleside='right'\n",
    "        ),\n",
    "        line_width=2))\n",
    "\n",
    "node_adjacencies = []\n",
    "node_text = []\n",
    "for node, adjacencies in enumerate(G.adjacency()):\n",
    "    node_adjacencies.append(len(adjacencies[1]))\n",
    "    node_text.append('# of connections: '+str(len(adjacencies[1])))\n",
    "\n",
    "node_trace.marker.color = node_adjacencies\n",
    "node_trace.text = node_text\n",
    "\n",
    "nlp_fig4 = go.Figure(data=[edge_trace, node_trace],\n",
    "             layout=go.Layout(\n",
    "                # title='Network graph made with Python',\n",
    "                titlefont_size=16,\n",
    "                showlegend=False,\n",
    "                hovermode='closest',\n",
    "                margin=dict(b=20,l=5,r=5,t=40),\n",
    "                # annotations=[ dict(\n",
    "                #     showarrow=False,\n",
    "                #     xref=\"paper\", yref=\"paper\",\n",
    "                #     x=0.005, y=-0.002 ) ],\n",
    "                xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "                yaxis=dict(showgrid=False, zeroline=False, showticklabels=False))\n",
    "                )\n",
    "\n",
    "\n",
    "app.layout = html.Div([\n",
    "    # Title\n",
    "    html.Div(\n",
    "        children=[\n",
    "            html.H1('Video Analysis',\n",
    "                    style={'textAlign': 'center'}),\n",
    "        ]),\n",
    "\n",
    "    # Upload Video\n",
    "    html.Div(\n",
    "        dcc.Upload(\n",
    "            id='upload-video',\n",
    "            children=html.Div([\n",
    "                'Drag and Drop or Select a Video',\n",
    "            ]),\n",
    "            style={\n",
    "                'width': '100%',\n",
    "                'height': '60px',\n",
    "                'lineHeight': '60px',\n",
    "                'borderWidth': '1px',\n",
    "                'borderStyle': 'dashed',\n",
    "                'borderRadius': '5px',\n",
    "                'textAlign': 'center',\n",
    "                'margin': '10px'\n",
    "            },\n",
    "            # Allow multiple files to be uploaded        \n",
    "            multiple=True,\n",
    "        ),\n",
    "        style={'display': 'flex', 'justifyContent': 'center', 'alignItems': 'center'}\n",
    "    ),\n",
    "\n",
    "    # Output Video\n",
    "    html.Div(id='output-video',\n",
    "             style={'display': 'flex', \n",
    "                    'justifyContent': 'space-around', \n",
    "                    'alignItems': 'center'}),\n",
    "    \n",
    "    html.Br(),\n",
    "    html.Br(),\n",
    "\n",
    "    # feature 1\n",
    "    html.Div(id='feature1',\n",
    "             children=[\n",
    "                 html.H2('Face Detection And Mesh'),\n",
    "                 dcc.Graph(id='graph1', \n",
    "                           figure=fig)\n",
    "             ]),\n",
    "    html.Br(),\n",
    "\n",
    "    # feature 2\n",
    "    html.Div(id='feature2',\n",
    "             children=[\n",
    "                 html.H2('Sentimental Analysis'),\n",
    "                 dcc.Graph(id='graph2', \n",
    "                           figure=fig)\n",
    "             ]),   \n",
    "\n",
    "    html.Br(),\n",
    "\n",
    "    # feature 3\n",
    "    html.Div(id='feature3',\n",
    "             children=[\n",
    "                 html.H2('Pose Detection'),\n",
    "                 dcc.Graph(id='graph3', \n",
    "                           figure=fig)\n",
    "             ]),  \n",
    "\n",
    "    html.Br(),\n",
    "\n",
    "    # feature 4\n",
    "    html.Div(id='feature4',\n",
    "             children=[\n",
    "                 html.H2('Face & Arm Detection'),\n",
    "                 dcc.Graph(id='graph4', \n",
    "                           figure=fig)\n",
    "             ]),   \n",
    "\n",
    "    html.Br(),\n",
    "\n",
    "    # NLP_feature 1\n",
    "    html.Div(id='NLP_feature 1',\n",
    "             children=[\n",
    "                 html.H2('The Most Frequent Words'),\n",
    "                 dcc.Graph(id='NLP_graph1', \n",
    "                           figure=nlp_fig1)\n",
    "             ]),   \n",
    "    # NLP_feature 2\n",
    "    html.Div(id='NLP_feature 2',\n",
    "             children=[\n",
    "                 html.H2('Histogram Of Word Length'),\n",
    "                 dcc.Graph(id='NLP_graph2', \n",
    "                           figure=nlp_fig2)\n",
    "             ]),   \n",
    "    # NLP_feature 3\n",
    "    html.Div(id='NLP_feature 3',\n",
    "             children=[\n",
    "                 html.H2('Heatmap Of Term Frequency'),\n",
    "                 dcc.Graph(id='NLP_graph3', \n",
    "                           figure=nlp_fig3)\n",
    "             ]),   \n",
    "    # NLP_feature 4\n",
    "    html.Div(id='NLP_feature 4',\n",
    "             children=[\n",
    "                 html.H2('Network Diagram'),\n",
    "                 dcc.Graph(id='NLP_graph4', \n",
    "                           figure=nlp_fig4)\n",
    "             ]),                                           \n",
    "\n",
    "])\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    Output('output-video', 'children'),\n",
    "    Input('upload-video', 'contents'),\n",
    "    prevent_initial_call=True\n",
    ")\n",
    "def to_postgre(list_of_contents):\n",
    "    if list_of_contents is not None:\n",
    "\n",
    "        ########### About Database ###########\n",
    "        # Connect to your postgres DB\n",
    "        conn = psycopg2.connect(\"dbname=VideoWeb user=postgres password=1q2w3e\")\n",
    "\n",
    "        # Open a cursor to perform database operations\n",
    "        cur = conn.cursor()\n",
    "\n",
    "        # Create table if it doesn't exist\n",
    "        cur.execute(\"CREATE TABLE IF NOT EXISTS video_metadata (id serial PRIMARY KEY, duration REAL, fps REAL, size TEXT, audio_fps REAL);\")\n",
    "\n",
    "\n",
    "        for contents in list_of_contents:\n",
    "            # The contents are base64 encoded, so we must decode them\n",
    "            decoded = base64.b64decode(contents.split(',')[1])\n",
    "\n",
    "            # Write the binary data to a file\n",
    "            with open('temp.mp4', 'wb') as f:\n",
    "                f.write(decoded)\n",
    "\n",
    "            # Read the video file and extract metadata\n",
    "            clip = VideoFileClip('temp.mp4')\n",
    "\n",
    "            # Extract metadata\n",
    "            duration = clip.duration\n",
    "            fps = clip.fps\n",
    "            size = str(clip.size)\n",
    "            audio_fps = clip.audio.fps if clip.audio is not None else None\n",
    "            audio_nchannels = clip.audio.nchannels if clip.audio is not None else None\n",
    "            audio_sample_width = clip.audio.sample_width if clip.audio is not None else None\n",
    "            audio_sample_rate = clip.audio.sample_rate if clip.audio is not None else None\n",
    "\n",
    "            # Insert the metadata into the database\n",
    "            cur.execute(\"INSERT INTO video_metadata (duration, fps, size, audio_fps) VALUES (%s, %s, %s, %s);\", (duration, fps, size, audio_fps))\n",
    "\n",
    "        ########### About Table ###########\n",
    "            # Create a DataFrame from the metadata\n",
    "            df = pd.DataFrame({\n",
    "                'Duration': [duration],\n",
    "                'FPS': [fps],\n",
    "                'Size': [size],\n",
    "                'Audio FPS': [audio_fps],\n",
    "                'Audio Channels': [audio_nchannels],\n",
    "                'Audio Sample Width': [audio_sample_width],\n",
    "                'Audio Sample Rate': [audio_sample_rate]\n",
    "            \n",
    "            })\n",
    "\n",
    "            # Transpose the DataFrame\n",
    "            df = df.transpose()\n",
    "            df.columns = ['Value']            \n",
    "\n",
    "            # Reset the index and rename the index column to 'Metadata'\n",
    "            df = df.reset_index().rename(columns={'index': 'Metadata'})            \n",
    "\n",
    "            # Create a DataTable from the DataFrame\n",
    "            table = dash_table.DataTable(\n",
    "                id='table',\n",
    "                columns=[{\"name\": i, \"id\": i} for i in df.columns],\n",
    "                data=df.to_dict('records'),\n",
    "            )                  \n",
    "\n",
    "        # Commit changes and close resources\n",
    "        conn.commit()\n",
    "        cur.close()\n",
    "        conn.close()    \n",
    "\n",
    "        children = [\n",
    "            html.Div(\n",
    "                children=[\n",
    "                    html.Video(src=contents, \n",
    "                               controls=True, \n",
    "                               style={'width': '100%'})\n",
    "                ],\n",
    "                style={'width': '50%'}\n",
    "            ),\n",
    "            html.Div(\n",
    "                children=[table],\n",
    "                style={'width': '50%'}\n",
    "            )\n",
    "        ]\n",
    "        return children\n",
    "    \n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lhs_3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
